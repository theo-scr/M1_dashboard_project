{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Install-/-Download-/-Import-Librairies\" data-toc-modified-id=\"Install-/-Download-/-Import-Librairies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Install / Download / Import Librairies</a></span></li><li><span><a href=\"#Connection-to-the-database\" data-toc-modified-id=\"Connection-to-the-database-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Connection to the database</a></span></li><li><span><a href=\"#Partie-1---Insertion-of-&quot;basic&quot;-information.\" data-toc-modified-id=\"Partie-1---Insertion-of-&quot;basic&quot;-information.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Partie 1 - Insertion of \"basic\" information.</a></span><ul class=\"toc-item\"><li><span><a href=\"#1-1)-Countries\" data-toc-modified-id=\"1-1)-Countries-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>1-1) Countries</a></span></li><li><span><a href=\"#1-2)-Brands\" data-toc-modified-id=\"1-2)-Brands-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>1-2) Brands</a></span></li><li><span><a href=\"#1-3)-Domains\" data-toc-modified-id=\"1-3)-Domains-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>1-3) Domains</a></span></li><li><span><a href=\"#1-4)-Vehicules\" data-toc-modified-id=\"1-4)-Vehicules-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>1-4) Vehicules</a></span></li><li><span><a href=\"#1-5)-Engines\" data-toc-modified-id=\"1-5)-Engines-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>1-5) Engines</a></span></li><li><span><a href=\"#1-6)-Technologies\" data-toc-modified-id=\"1-6)-Technologies-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>1-6) Technologies</a></span></li></ul></li><li><span><a href=\"#Partie-2---Insertion-of-&quot;scraping&quot;-information.\" data-toc-modified-id=\"Partie-2---Insertion-of-&quot;scraping&quot;-information.-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Partie 2 - Insertion of \"scraping\" information.</a></span><ul class=\"toc-item\"><li><span><a href=\"#2-1)-Authors\" data-toc-modified-id=\"2-1)-Authors-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>2-1) Authors</a></span></li><li><span><a href=\"#2-2)-Articles\" data-toc-modified-id=\"2-2)-Articles-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>2-2) Articles</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDFCWZM1F9q2"
   },
   "source": [
    "# Install / Download / Import Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8KNadDySF9q4"
   },
   "outputs": [],
   "source": [
    "# Text librairy\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Useful librairies\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Module for access to Oracle database\n",
    "import cx_Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "NbSK1wRYF9q-",
    "outputId": "520868d9-3b4e-4cc4-b73b-7f398d56cdbf"
   },
   "outputs": [],
   "source": [
    "# Connection to the database 'SCT2985A'.\n",
    "mydb = cx_Oracle.connect('SCT2985A/esg@//telline.univ-tlse3.fr:1521/etupre',\n",
    "                         encoding='UTF-8',\n",
    "                         nencoding=\"UTF-8\")\n",
    "\n",
    "# Creation of the cursor. It is used to execute statements to communicate with the Oracle database.\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 - Insertion of \"basic\" information. \n",
    "Insertion of information that does not require the content of the scraping files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8GgK-kZOhTG9"
   },
   "outputs": [],
   "source": [
    "def insert(sql_request: str, list_items: list):\n",
    "    \"\"\" Documentation :\n",
    "            - Function allowing to make a data insertion request in the database. The primary key is an\n",
    "            identifier that is manually incremented at each insertion. \n",
    "\n",
    "        Parameters:\n",
    "            - sql_request : insertion request in SQL language.\n",
    "            - list_items : list of items to insert in the database. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of the identifier\n",
    "    id = 0\n",
    "\n",
    "    # Browse the list\n",
    "    for item in tqdm(list_items):\n",
    "\n",
    "        # The values to be inserted are the identifier and the current value of the list (item).\n",
    "        values = [id, item]\n",
    "        # Execution of the request\n",
    "        mycursor.execute(sql_request, values)\n",
    "        # Incrementing of the identifier\n",
    "        id += 1\n",
    "\n",
    "    # Once all the insertions are done, we make a commit\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1) Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Tw1ZEuvWF9rF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:08<00:00, 23.79it/s]\n"
     ]
    }
   ],
   "source": [
    "list_countries_BD = [\"Algérie\", \"Angola\", \"Bénin\", \"Botswana\", \"Burkina Faso\", \"Burundi\", \"Cameroun\", \"Cap vert\",\n",
    "                     \"République centrafricaine\", \"Tchad\", \"Comores\", \"Congo\", \"Djibouti\", \"Egypte\",\n",
    "                     \"Guinée équatoriale\", \"Erythree\", \"Ethiopie\", \"Gabon\", \"Gambie\", \"Ghana\", \"Guinée\",\n",
    "                     \"Guinée-Bissau\", \"Côte d'Ivoire\", \"Kenya\", \"Lesotho\", \"Liberia\", \"Libye\", \"Madagascar\",\n",
    "                     \"Malawi\", \"Mali\", \"Mauritanie\", \"Ile Maurice\", \"Maroc\", \"Mozambique\", \"Namibie\", \"Niger\",\n",
    "                     \"Nigeria\", \"Rwanda\", \"Sao Tomé-et-Principe\", \"Sénégal\", \"Seychelles\", \"Sierra Leone\",\n",
    "                     \"Somalie\", \"Afrique du Sud\", \"Soudan\", \"Swaziland\", \"Tanzanie\", \"Togo\", \"Tunisie\", \"Ouganda\",\n",
    "                     \"Zambie\", \"Zimbabwe\", \"Albanie\", \"Andorre\", \"Arménie\", \"Autriche\", \"Azerbaijan\",\n",
    "                     \"Biélorussie\", \"Belgique\", \"Bosnie\", \"Bulgarie\", \"Croatie\", \"Chypre\", \"République Tchèque\",\n",
    "                     \"Danemark\", \"Estonie\", \"Finlande\", \"France\", \"Angleterre\", \"Ecosse\", \"Pays de Galles\",\n",
    "                     \"Géorgie\", \"Allemagne\", \"Grèce\", \"Hongrie\", \"Islande\", \"Irelande\", \"Italie\", \"Lettonie\",\n",
    "                     \"Liechtenstein\", \"Lituanie\", \"Luxembourg\", \"Macédoine\", \"Malte\", \"Moldavie\", \"Monaco\",\n",
    "                     \"Montenegro\", \"Pays-Bas\", \"Norvège\", \"Pologne\", \"Portugal\", \"Roumanie\", \"Saint-Marin\",\n",
    "                     \"Serbie\", \"Slovaquie\", \"Slovénie\", \"Espagne\", \"Suède\", \"Suisse\", \"Ukraine\", \"Royaume-Uni\",\n",
    "                     \"Vatican\", \"Antigua-et-Barbuda\", \"Bahamas\", \"La Barbade\", \"Belize\", \"Canada\", \"Costa Rica\",\n",
    "                     \"Cuba\", \"Dominique\", \"République dominicaine\", \"El Salvador\", \"Grenade\", \"Guatemala\", \"Haiti\",\n",
    "                     \"Honduras\", \"Jamaique\", \"Mexique\", \"Nicaragua\", \"Paname\", \"Saint-Christophe et Niévès\",\n",
    "                     \"Saint Lucie\", \"Saint Vincent et les Grenadines\", \"Trinidad et Tobago\", \"Etats-Unis\",\n",
    "                     \"Argentine\", \"Bolivie\", \"Brésil\", \"Chili\", \"Colombie\", \"Equateur\", \"Guyane\", \"Paraguay\",\n",
    "                     \"Pérou\", \"Suriname\", \"Uruguay\", \"Venezuela\", \"Afghanistan\", \"Bahrein\", \"Bangladesh\",\n",
    "                     \"Bhoutan\", \"Brunei\", \"Myanmar\", \"Cambodge\", \"Chine\", \"Timor oriental\", \"Inde\", \"Indonésie\",\n",
    "                     \"Iran\", \"Irak\", \"Israël\", \"Japon\", \"Jordanie\", \"Kazakhstan\", \"Corée du Sud\", \"Corée du Nord\",\n",
    "                     \"Koweït\", \"Kyrgyzstan\", \"Laos\", \"Liban\", \"Malaysie\", \"Maldives\", \"Mongolie\", \"Népal\", \"Oman\",\n",
    "                     \"Pakistan\", \"Palestine\", \"Philippines\", \"Qatar\", \"Russie\", \"Arabie Saoudite\", \"Singapour\",\n",
    "                     \"Sri Lanka\", \"Syrie\", \"Tajikistan\", \"Thaïlande\", \"Turquie\", \"Turkmenistan\",\n",
    "                     \"Emirats Arabes Unis\", \"Ouzbekistan\", \"Viêtnam\", \"Yémen\", \"Australie\", \"Fiji\",\n",
    "                     \"République de Kiribati\", \"Iles Marshall\", \"Micronésie\", \"Nauru\", \"Nouvelle-Zélande\", \"Palau\",\n",
    "                     \"Papouasie Nouvelle Guinée\", \"Iles Samoa\", \"Iles Salomon\", \"Tonga\", \"Tuvalu\", \"Vanuatu\",\n",
    "                     \"République Democratique du Congo\"]\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Pays VALUES ( :1, :2)\"\n",
    "\n",
    "# Fonction 'insert' for the table \"Pays\"\n",
    "insert(sql_request, list_countries_BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2) Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rbKNM3P7HnXx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 23.74it/s]\n"
     ]
    }
   ],
   "source": [
    "list_brands_BD = [\"Hyundai\", \"Toyota\", \"Renault\", \"Honda\", \"Airbus\", \"Boeing\", \"Thalès\", \"Mercedes\", \"Audi\", \"Kia\",\n",
    "                  \"Riversimple\", \"Nissan\", \"Ford\", \"Daimler\", \"Alstom\", \"BMW\", \"Hopium\", \"Peugeot\", \"Volkswagen\",\n",
    "                  \"General Motors\", \"PSA\", \"Roland Gumpert\", \"Mazda\", \"Aston Martin\", \"Pininfarina\", \"Suzuki\",\n",
    "                  \"Volvo\", \"Opel\", \"Dassault\", \"Cessna\", \"Bombardier\", \"MiG\", \"Diamond Aircraft\", \"ZeroAvia\",\n",
    "                  \"Rolls-Royce\", \"Eviation\", \"Khrounitchev\", \"SpaceX\", \"Avio\", \"ArianeGroup\",\n",
    "                  \"United Launch Alliance\", \"McDonnell Douglas\", \"Mitsubishi Heavy Industries\", \"ISRO\",\n",
    "                  \"Ioujnoie\", \"Citroën\", \"Fiat\", \"Lancia\", \"Skoda\", \"Yamaha\", \"KTM\", \"Kawasaki\", \"Ducati\",\n",
    "                  \"Suzuki\"]\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Marque VALUES ( :1, :2)\"\n",
    "\n",
    "# Fonction 'insert' for the table \"Marque\"\n",
    "insert(sql_request, list_brands_BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3) Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IigkDQoShFay"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 23.39it/s]\n"
     ]
    }
   ],
   "source": [
    "list_domains_BD = [\"Militaire\", \"Agriculture\", \"Astronautique\", \"Aéronautique\", \"Transport Marchandises\",\n",
    "                   \"Transport Personnes\", \"Politique\", \"Automobile\", \"Ferroviaire\", \"Energies Renouvelables\",\n",
    "                   \"Energies Fossiles\", \"Performance\", \"Chimie\"]\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Domaine VALUES ( :1, :2)\"\n",
    "\n",
    "# Fonction 'insert' for the table \"Domaines\"\n",
    "insert(sql_request, list_domains_BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4) Vehicules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nEPT7wWAh7Cz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 23.51it/s]\n"
     ]
    }
   ],
   "source": [
    "list_vehicules_BD = [\"Train\", \"Tracteur\", \"Vélo\", \"Bateau\", \"Avion\", \"Voiture\", \"Camion\", \"Bus\", \"Fusée\",\n",
    "                     \"Hélicoptère\", \"Moto\", \"Tramway\", \"Sous-marin\"]\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Vehicule VALUES ( :1, :2)\"\n",
    "\n",
    "# Fonction 'insert' for the table \"Vehicules\"\n",
    "insert(sql_request, list_vehicules_BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5) Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pIUlMAJ4h7Gc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "list_moteur_BD = [\"Combustion interne\",\n",
    "                  \"Réaction\",  \"Pile à combustible\", \"Hybride\"]\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Moteur  VALUES ( :1, :2)\"\n",
    "\n",
    "# Fonction 'insert' for the table \"Moteur\"\n",
    "insert(sql_request, liste_moteur_BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhLnTA53_E2-"
   },
   "source": [
    "## 1-6) Technologies\n",
    "Table different from the previous ones: there are 4 attributes. So we cannot use the 'insert' function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y1USNNk0h6_8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Several lists to differentiate technologies (storage or production and type of production).\n",
    "# This will allow the right values to be set for the attributes.\n",
    "list_type_prod_BD_H = [\"SMR\", \"Pyrolyse du méthane\", \"Oxydation partielle\", \"Reformage plasma\",\n",
    "                       \"Gazéification du charbon\"]\n",
    "\n",
    "list_type_prod_BD_E = [\"Electrolyse\", \"Electrochimie\", \"Radiolyse\", \"Thermolyse\", \"Thermochimie\",\n",
    "                       \"Ferrosilicium\", \"Culture d'algues\", \"Fission photocatalytique\"]\n",
    "\n",
    "list_type_prod_BD_A = [\"Fermentation\", \"Production enzymatique\",\n",
    "                       \"Electrolyse biocatalysée\"]\n",
    "\n",
    "list_storage_BD = ['Gaz', 'Liquide', 'Solide']\n",
    "\n",
    "\n",
    "# SQL request\n",
    "sql_request = \"INSERT INTO Technologie VALUES ( :1, :2, :3, :4)\"\n",
    "\n",
    "# Initialization of identifiant and cumpter\n",
    "id_techno = 0\n",
    "cpt = 0\n",
    "\n",
    "# The 4 types of lists are browsed\n",
    "for list_tech in tqdm([liste_type_prod_BD_H, liste_type_prod_BD_E, liste_type_prod_BD_A, liste_stockage_BD]):\n",
    "\n",
    "    # If cpt is not equal to 3, it's a production technology\n",
    "    if (cpt != 3):\n",
    "        cat = 'Production'\n",
    "    # Else it's a storage technology\n",
    "    else:\n",
    "        cat = 'Stockage'\n",
    "\n",
    "    # If cpt is equal to 0, the source is Hydraucarbon\n",
    "    if (cpt == 0):\n",
    "        source = 'Hydraucarbures'\n",
    "    # If cpt equals 1, the source is Water\n",
    "    elif (cpt == 1):\n",
    "        source = 'Eau'\n",
    "    # If cpt is equal to 2, the source is Other\n",
    "    elif (cpt == 2):\n",
    "        source = 'Autre'\n",
    "    # Else there is no source.\n",
    "    else:\n",
    "        source = None\n",
    "\n",
    "    # The technology list is browsed and inserted into the BD\n",
    "    for techno in list_tech:\n",
    "        values = [id_techno, techno, cat, source]\n",
    "        mycursor.execute(sql_request, values)\n",
    "        id_techno += 1\n",
    "\n",
    "    # Incrementation of cpt since we change of list\n",
    "    cpt += 1\n",
    "\n",
    "# Once all the insertions are done, we make a commit\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 - Insertion of \"scraping\" information. \n",
    "Insertion of information that require the content of the scraping files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8439, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The information contained in the 'df_scraping.csv' file (created with the 'scraping_v1.4' notebook) is\n",
    "# recovered in a dataframe.\n",
    "df = pd.read_csv(\"../scraping/df_scraping.csv\",\n",
    "                 sep=',', index_col=False, encoding='utf-8')\n",
    "\n",
    "# Check the dimensions of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) Authors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IsuAv9Kwh7Jk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [16:23<00:00,  8.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Initialization of useful variables.\n",
    "sql_request_authors = \"INSERT INTO Auteur  VALUES ( :1, :2)\"  # SQL requests\n",
    "id_authors = 0  # authors identifier\n",
    "\n",
    "# Set to avoid reinserting an author several times\n",
    "authors_already_inserted = set()\n",
    "\n",
    "# Dictionary to find the names of authors. For example, in the database, \"오진숙\" will be coded as\n",
    "# \"\\xec\\x98\\xa4\\xec\\xa7\\x84\\xec\\x88\\x99\". Thanks to this dictionary, we will be able to find the real name\n",
    "# of the authors with special characters when viewing the data.\n",
    "author_utf8 = dict()\n",
    "\n",
    "# Browse the list of authors\n",
    "for authors in tqdm(df['Auteur']):\n",
    "\n",
    "    # If the information for the current article is not None\n",
    "    if (authors is not np.nan):\n",
    "\n",
    "        # Separate authors with the 'and' separation (see the Scraping Notebook)\n",
    "        authors = authors.split(' and ')\n",
    "\n",
    "        # Cleaning up names :\n",
    "        # - Remove numbers and special characters\n",
    "        # - Put everything in lower case, then put only the first letter in upper case\n",
    "        authors = [re.sub(\"([0-9]|(\\((.*?)\\))|\\-|\\(|\\)|#|\\?|&|\\[|\\]|�|!)\",\n",
    "                          \"\", author).lower().strip().title() for author in auteurs]\n",
    "\n",
    "        # - Finally, we remove the spaces before and after.\n",
    "        authors = [' '.join(author.split()) for author in authors]\n",
    "\n",
    "        # Browse all authors who have written the current article\n",
    "        for author in authors:\n",
    "\n",
    "            # We check that it has not already been inserted and that the length of its name\n",
    "            # is not just a character or an empty string.\n",
    "            if author not in authors_already_inserted and len(author) > 2:\n",
    "                # It is added to the set\n",
    "                authors_already_inserted.add(author)\n",
    "\n",
    "                # We try to encode it in 'Ascii', if we can't do it, it contains special characters.\n",
    "                # It must therefore be encoded with the 'UTF-8' format and added to the dictionary (see\n",
    "                # explanation above).\n",
    "                try:\n",
    "                    author_BD = str(author.encode('ascii'))[2:-1]\n",
    "                except:\n",
    "                    author_BD = str(author.encode())[2:-1]\n",
    "                    author_utf8[auteur] = author_BD\n",
    "\n",
    "                # The values to be inserted are the identifier and the name of auteur.\n",
    "                values = [id_authors, author_BD]\n",
    "                # Execution of the request\n",
    "                mycursor.execute(sql_request_authors, values)\n",
    "                # Incrementing of the identifier\n",
    "                id_authors += 1\n",
    "\n",
    "# Once all the insertions are done, we make a commit\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, a function will be needed to clean up the dates and have a uniform format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer(date: str) -> str:\n",
    "    \"\"\"\n",
    "        Documentation :\n",
    "            - Function that standardises the format of dates. \n",
    "\n",
    "        Parameter :\n",
    "            - date : date in raw format. \n",
    "\n",
    "        Output :\n",
    "            - date_clean : date in 'day/month/year' format. \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the date is in 'str' format (i.e. that it is not None)\n",
    "    if (type(date) == str):\n",
    "\n",
    "        # Most of the scraped dates are in 'year-month-day' format.\n",
    "        # Simply retrieve each element and put it back in the order that we want.\n",
    "        if (len(date) == 10 and date[4] == '-' and date[7] == '-'):\n",
    "            annee = date[:4]\n",
    "            mois = date[5:7]\n",
    "            jour = date[-2:]\n",
    "\n",
    "            # Sometimes there is no day and/or month and the value is 00.\n",
    "            # If this is the case, we change it to 01 (we will do our analysis on years only)\n",
    "            if (int(mois) < 1 or int(mois) > 12):\n",
    "                mois = '01'\n",
    "            if (int(jour) < 1 or int(jour) > 31):\n",
    "                jour = '01'\n",
    "\n",
    "            date_clean = jour + '-' + mois + '-' + annee\n",
    "\n",
    "        # Another format is \"[year]\". Just get the year in square brackets and put 01 for the day and month\n",
    "        elif (len(date) == 6 and date[0] == '[' and date[-1] == ']'):\n",
    "            annee = date[1:-1]\n",
    "            date_clean = '01-01-' + annee\n",
    "\n",
    "        # If the date is of length 4 and contains 19** or 20**, it is a year.\n",
    "        elif (len(date) == 4 and ('19' in date or '20' in date)):\n",
    "            date_clean = '01-01-' + date\n",
    "\n",
    "        # If it is another format than the three above, we just look if there is a year present (19** or 20**).\n",
    "        elif (re.search(\"(19|20)[0-9]{2}\", date) is not None):\n",
    "            pos = re.search(\"(19|20)[0-9]{2}\", date).start()\n",
    "            annee = date[pos:pos+4]\n",
    "            date_clean = '01-01-' + annee\n",
    "            \n",
    "        # Otherwise we can't determine the date, we return None \n",
    "        else:\n",
    "            date_clean = None\n",
    "    else:\n",
    "        date_clean = None\n",
    "\n",
    "    # date in 'day/month/year' format (or None)\n",
    "    return date_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_2w6QwPk-hcR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [06:48<00:00, 20.68it/s]  \n"
     ]
    }
   ],
   "source": [
    "# The previous function is applied to each date.\n",
    "dates = df['Date'].apply(lambda x: nettoyer(x))\n",
    "\n",
    "# For all titles, we put them all in lower case except the first letter (to standardize)\n",
    "titles = df['Titre'].apply(lambda x: None if (\n",
    "    x is np.nan) else x.lower().capitalize())\n",
    "\n",
    "# For languages, np.nan and 'Undetermined' are replaced by None\n",
    "langages = df['Langue'].apply(lambda x: None if x == 'Undetermined' else x).apply(\n",
    "    lambda x: None if (x is np.nan) else x)\n",
    "\n",
    "# SQL request \n",
    "sql_request_articles = \"INSERT INTO Article  VALUES ( :1, :2, :3, :4)\"\n",
    "\n",
    "# Note: a 'drop duplicate' has been performed beforehand => no risk of duplication\n",
    "for id, title, langage, date in zip(tqdm(df['Id']), titles, langages, dates):\n",
    "    \n",
    "    # The values to be inserted are the identifier, the title, the langage and the date.\n",
    "    values = [id, title, langage, date]\n",
    "\n",
    "    # Execution of the request\n",
    "    mycursor.execute(sql_request_articles, values)\n",
    "\n",
    "# Once all the insertions are done, we make a commit\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJJD86LOh7Mv"
   },
   "outputs": [],
   "source": [
    "# MOT CLE\n",
    "# nétoyyer mot clé => enlever ponctuation (pas toutes ! mais les parentèses pâs les - )\n",
    "# enelver espace avant après (et en trop au milieu)\n",
    "# majuscule ? \n",
    "# voir NLP comment netoyyer mot OU \n",
    "# fonction tanguy porjet interpromo ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanning(item: str, special_character: list):\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    item: str = item.lower()\n",
    "\n",
    "    iteam: str = re.sub(\"((\\((.*?)\\))|)\", \"\", item)\n",
    "\n",
    "    # Step 1 : Remove accents\n",
    "    item = unicodedata.normalize('NFD', str(item)).encode(\n",
    "        'ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "    # Step 2 : Remove Special character\n",
    "    for i in special_character:\n",
    "\n",
    "        item = item.replace(i, \"\")\n",
    "\n",
    "    # Remove whitespaces\n",
    "    item = item.strip()\n",
    "    result = ' '.join(item.split())\n",
    "\n",
    "    # Return my cleaned article\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_character: list = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"\\\\\", \"(\",\n",
    "                           \")\", \"*\", \"+\", \",\", \"-\", \".\", \":\", \";\",\n",
    "                           \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\",\n",
    "                           \"{\", \"|\", \"}\", \"~\", \"«\", \"»\", \"’\", \"•\", \"…\",\n",
    "                           \"â\", \"€\", \"™\", \"—\", \"�\", \"–\", \"“\", \"”\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_motcle = df['MotCle']\n",
    "\n",
    "col_motcle = col_motcle.apply(\n",
    "    lambda x: x if x is np.nan else cleanning(x, special_character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       renewable energy / wind power / land use / ene...\n",
       "1                                                     NaN\n",
       "2                                   faculty research day/\n",
       "3       road transportportugal/ pollutant emissions/ c...\n",
       "4       130 mechanical/ industrial/ civil and marine e...\n",
       "                              ...                        \n",
       "8434                                                  NaN\n",
       "8435                                                  NaN\n",
       "8436                                                  NaN\n",
       "8437                                                  NaN\n",
       "8438                                                  NaN\n",
       "Name: MotCle, Length: 8439, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_motcle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [03:47<00:00, 37.02it/s]  \n"
     ]
    }
   ],
   "source": [
    "# MOTS CLES '\n",
    "mots_deja_inseres = set()\n",
    "id_mot = 0\n",
    "sql_request = \"INSERT INTO MotCle  VALUES ( :1, :2)\"\n",
    "\n",
    "for mots in tqdm(col_motcle):\n",
    "    if (mots is not np.nan):\n",
    "        mots = mots.split('/')\n",
    "\n",
    "        # Supprimer les espaces en trop\n",
    "        mots = [' '.join(elem.split()) for elem in mots]\n",
    "\n",
    "        for mot in mots:\n",
    "            mot = mot.capitalize()\n",
    "\n",
    "            if mot not in mots_deja_inseres and len(mot) > 2 and len(mot) < 150:\n",
    "                mots_deja_inseres.add(mot)\n",
    "                values = [id_mot, mot]\n",
    "                mycursor.execute(sql_request, values)\n",
    "                id_mot += 1\n",
    "\n",
    "# On commit\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5859"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mots_deja_inseres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert2(relation, col, att, nom_id_att):\n",
    "    sql_request = \"INSERT INTO \" + relation + \"_Evoq VALUES ( :1, :2)\"\n",
    "    for chaine_att, id in zip(tqdm(df[col]), df['Id']):\n",
    "\n",
    "        if (chaine_att is not np.nan):\n",
    "            liste_att = chaine_att.split('/')\n",
    "            liste_att = [elem for elem in liste_att if len(elem) > 1]\n",
    "\n",
    "            for elem in liste_att:\n",
    "                elem = elem.replace(\"'\", \"''\")\n",
    "                sql_request_select = \"SELECT \" + nom_id_att + \" FROM \" + \\\n",
    "                    relation + \" WHERE \" + att + \" = '\" + elem + \"'\"\n",
    "                res = mycursor.execute(sql_request_select)\n",
    "                id_att = [row[0] for row in res][0]\n",
    "                values = [id, id_att]\n",
    "                mycursor.execute(sql_request, values)\n",
    "\n",
    "    # On commit\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [04:00<00:00, 35.06it/s] \n"
     ]
    }
   ],
   "source": [
    "insert2(\"Pays\", \"Pays\", \"nom_pays\", \"id_pays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [06:32<00:00, 21.48it/s]  \n"
     ]
    }
   ],
   "source": [
    "insert2(\"Moteur\", \"Moteur\", \"type_moteur\", \"id_moteur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [04:37<00:00, 30.43it/s] \n"
     ]
    }
   ],
   "source": [
    "insert2(\"Vehicule\", \"Vehicule\", \"type_vehicule\", \"id_vehicule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [06:33<00:00, 21.47it/s]\n"
     ]
    }
   ],
   "source": [
    "insert2(\"Domaine\", \"Domaine\", \"nom_domaine\", \"id_domaine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [01:17<00:00, 108.70it/s]\n"
     ]
    }
   ],
   "source": [
    "insert2(\"Marque\", \"Marque\", \"nom_marque\", \"id_marque\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [04:06<00:00, 34.24it/s]\n"
     ]
    }
   ],
   "source": [
    "insert2(\"Technologie\", \"Stockage\", \"nom_tech\", \"id_tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [03:16<00:00, 43.04it/s] \n"
     ]
    }
   ],
   "source": [
    "insert2(\"Technologie\", \"Production\", \"nom_tech\", \"id_tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [22:43<00:00,  6.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "sql_request = \"INSERT INTO MotsCle_Evoq VALUES ( :1, :2)\"\n",
    "\n",
    "for chaine_mot, id in zip(tqdm(col_motcle), df['Id']):\n",
    "\n",
    "    if (chaine_mot is not np.nan):\n",
    "        mots = chaine_mot.split('/')\n",
    "        mots = [elem for elem in mots if len(elem) > 1]\n",
    "\n",
    "        # Supprimer les espaces en trop\n",
    "        mots = [' '.join(elem.split()) for elem in mots]\n",
    "\n",
    "        # enlever les doublons eventuels -> pb de doublement de PK sinon\n",
    "        mots = list(set(mots))\n",
    "\n",
    "        for mot in mots:\n",
    "            mot = mot.capitalize()\n",
    "            if len(mot) > 2 and len(mot) < 150:\n",
    "                mot = mot.replace(\"'\", \"''\")\n",
    "                sql_request_select = \"SELECT id_motcle FROM Motcle WHERE mot = '\" + mot + \"'\"\n",
    "                res = mycursor.execute(sql_request_select)\n",
    "                id_att = [row[0] for row in res][0]\n",
    "                values = [id, id_att]\n",
    "                mycursor.execute(sql_request, values)\n",
    "\n",
    "    # On commit\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [24:49<00:00,  2.68it/s]  \n",
      "100%|██████████| 4439/4439 [33:00<00:00,  2.24it/s]  \n"
     ]
    }
   ],
   "source": [
    "sql_request = \"INSERT INTO Auteur_Evoq VALUES ( :1, :2)\"\n",
    "\n",
    "auteur1 = df[\"Auteur\"].iloc[:4000]\n",
    "id1 = df['Id'].iloc[:4000]\n",
    "auteur2 = df[\"Auteur\"].iloc[4000:]\n",
    "id2 = df['Id'].iloc[4000:]\n",
    "\n",
    "for col_att, col_id in zip([auteur1, auteur2], [id1, id2]):\n",
    "    for chaine_att, id in zip(tqdm(col_att), col_id):\n",
    "\n",
    "        if (chaine_att is not np.nan):\n",
    "            liste_att = chaine_att.split(' and ')\n",
    "            # on enlève nb et caractère spéciaux\n",
    "            # mets en minuscule tout, puis mets que les première lettre en majuscule puis enlèev espace avant et après\n",
    "            liste_att = [re.sub(\"([0-9]|(\\((.*?)\\))|\\-|\\(|\\)|#|\\?|&|\\[|\\]|�|!)\",\n",
    "                                \"\", elem).lower().strip().title() for elem in liste_att]\n",
    "            liste_att = [' '.join(elem.split()) for elem in liste_att]\n",
    "            liste_att = [elem for elem in liste_att if len(elem) > 2]\n",
    "\n",
    "            # enlever les doublons eventuels -> pb de doublement de PK sinon\n",
    "            liste_att = list(set(liste_att))\n",
    "\n",
    "            for elem in liste_att:\n",
    "                try:\n",
    "                    elem = str(elem.encode('ascii'))[2:-1]\n",
    "\n",
    "                except:\n",
    "                    elem = str(elem.encode())[2:-1]\n",
    "                elem = elem.replace(\"'\", \"''\")\n",
    "\n",
    "                sql_request_select = \"SELECT id_auteur FROM Auteur WHERE nom_prenom = '\" + elem + \"'\"\n",
    "                res = mycursor.execute(sql_request_select)\n",
    "                id_att = [row[0] for row in res][0]\n",
    "                values = [id, id_att]\n",
    "                mycursor.execute(sql_request, values)\n",
    "\n",
    "    # On commit\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8439/8439 [05:19<00:00, 26.41it/s]  \n"
     ]
    }
   ],
   "source": [
    "# sql_request = \"INSERT INTO Pays_Evoq VALUES ( :1, :2)\"\n",
    "\n",
    "# for chaine_pays,id in zip(tqdm(df['Pays']), df['Id']):\n",
    "    \n",
    "#     if (chaine_pays is not np.nan):\n",
    "#         liste_pays = chaine_pays.split('/')\n",
    "#         liste_pays = [pays for pays in liste_pays if len(pays)>1]\n",
    "        \n",
    "#         for pays in liste_pays : \n",
    "#             sql_request_select = \"SELECT id_pays FROM Pays WHERE nom_pays = '\"+ pays +\"'\"\n",
    "#             res = mycursor.execute(sql_request_select)\n",
    "#             id_pays = [row[0] for row in res][0]\n",
    "#             values = [id, id_pays]\n",
    "#             mycursor.execute(sql_request, values)\n",
    "            \n",
    "# # On commit\n",
    "# mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d2uUxxn8I-HV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_request = \"SELECT id_pays FROM Pays WHERE nom_pays = 'France'\"\n",
    "# res = mycursor.execute(sql_request)\n",
    "# id_pays = [row[0] for row in res][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "insertion_BD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
